{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HKCN-6C1ejO"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "from .utils._logger import logger\n",
    "from .utils._validation import config_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from pandas import DataFrame\n",
    "\n",
    "try:\n",
    "    df: DataFrame = pd.read_csv(config_args.data_path)\n",
    "    logger.info(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Error: CSV file not found.  Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "df = df.set_index(\"car_ID\")\n",
    "\n",
    "logger.info(f\"Initial DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"Missing values found. Imputation will be performed.\")\n",
    "    logger.warning(\"Missing values found. Imputation will be performed.\")\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "    logger.info(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspection\n",
    "df.info()\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df[\"brand\"] = df[\"CarName\"].str.split(\" \", n=1, expand=True)[0]\n",
    "df[\"model\"] = df[\"CarName\"].str.split(\" \", n=1, expand=True)[1].str.replace(\" \", \"\")\n",
    "\n",
    "df = df.drop(\"CarName\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring columns\n",
    "numeric_cols = [\n",
    "    col\n",
    "    for col in df.columns\n",
    "    if pd.api.types.is_numeric_dtype(df[col]) and col != \"price\"\n",
    "]\n",
    "categorical_cols = [\n",
    "    col for col in df.columns if col not in numeric_cols and col != \"price\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(np.abs(stats.zscore(df[numeric_cols])) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "logger.info(\"Applying One-Hot Encoding...\")\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    [(\"onehot\", encoder, categorical_cols)], remainder=\"passthrough\"\n",
    ")\n",
    "df_processed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(df), columns=preprocessor.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols: list[str] = [\n",
    "    column for column in list(df_processed.columns) if not column.startswith(\"onehot\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Numeric Features\n",
    "scaler = StandardScaler()\n",
    "df_processed[numeric_cols] = scaler.fit_transform(df_processed[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X = df_processed\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "pickle.dump(model, open(config_args.save_model_name, \"wb\"))\n",
    "logger.info(f\"Model saved to {config_args.save_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMW3OX7jjMk2Zt+pYR5wDrJ",
   "mount_file_id": "15XyHsFOsrkx_a9Xw9hpnnw1Wkr3Pa6zK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
